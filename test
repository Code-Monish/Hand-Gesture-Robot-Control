import cv2
import mediapipe as mp
import numpy as np

def pad_image(img, pad_size):
    return np.pad(img, ((pad_size, pad_size), (pad_size, pad_size)), mode='constant', constant_values=0)

def apply_filter(f_transform, filter_type='low', radius=30):
    rows, cols = f_transform.shape
    crow, ccol = rows // 2, cols // 2

    mask = np.zeros((rows, cols), np.uint8)

    if filter_type == 'low':
        cv2.circle(mask, (ccol, crow), radius, 1, thickness=-1)
    elif filter_type == 'high':
        mask[:] = 1
        cv2.circle(mask, (ccol, crow), radius, 0, thickness=-1)

    return f_transform * mask

mp_hands = mp.solutions.hands
hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1)
mp_draw = mp.solutions.drawing_utils

cap = cv2.VideoCapture(0)

while True:
    success, img = cap.read()
    if not success:
        break

    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    resized = cv2.resize(img_gray, (150, 140))

    pad_size = 20
    padded = pad_image(resized, pad_size)

    f_transform = np.fft.fft2(padded)
    f_shift = np.fft.fftshift(f_transform)
    magnitude_spectrum = 20 * np.log(np.abs(f_shift) + 1)  # avoid log(0)
    magnitude_spectrum = np.uint8(np.clip(magnitude_spectrum, 0, 255))
    cv2.imshow("FFT Magnitude", magnitude_spectrum)

    filtered_freq = apply_filter(f_shift, filter_type='low', radius=30)

    f_ishift = np.fft.ifftshift(filtered_freq)
    img_back = np.fft.ifft2(f_ishift)
    img_back = np.real(img_back)
    filtered_magnitude = 20 * np.log(np.abs(filtered_freq) + 1)
    filtered_magnitude = np.uint8(np.clip(filtered_magnitude, 0, 255))
    cv2.imshow("Filtered FFT", filtered_magnitude)

    cropped = img_back[pad_size:-pad_size, pad_size:-pad_size].astype(np.uint8)

    display_img = cv2.cvtColor(cropped, cv2.COLOR_GRAY2BGR)

    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    results = hands.process(img_rgb)

    if results.multi_hand_landmarks:
        for hand_landmarks in results.multi_hand_landmarks:
            mp_draw.draw_landmarks(display_img, hand_landmarks, mp_hands.HAND_CONNECTIONS)

    cv2.imshow("Processed Hand Gesture", display_img)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
